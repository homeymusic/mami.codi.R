---
title: "MaMi.CoDi: A Spatiotemporal Periodicity Model of Consonance Perception"
output:
  github_document: default
---

```{r, echo=F, message=F, include=F}
devtools::load_all(".")
source('./man/code/plot.R')
source('./man/code/utils.R')
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  warning = FALSE, 
  message = FALSE
)
BEHAVIOURAL_SMOOTH_BROAD  <- 0.2
BEHAVIOURAL_SMOOTH_NARROW <- 0.035
```

## How MaMi.CoDi Works

```{r, child=c('man/Spatiotemporal_Periodicity.Rmd')}
```

### Finding the Tolerance Values

MaMi.CoDi uses the Stern-Brocot tree to find rational fractions for the ratios 
within a given tolerance. How do we find the best tolerance values? For the 
MaMi.CoDi model we ran thousands of computations with various tolerance values 
and compared the predictions with results from six of the large-scale behavioral 
experiments.\

Because spatial and temporal information is encoded via different mechanisms by 
the cochlea, we assumed that the wavelength and frequency tolerances would have 
different values.\

So, our tolerance searches were two-dimensional. We searched for combinations 
of frequency tolerance and wavelength tolerance. The image below is a sample of 
a 2D tolerance search using the harmonic experiment from large-scale behavioral study.\

![Two-dimensional tolerance search for frequency and wavelength tolerance values for finding rational fractions for tone ratios.](https://github.com/homeymusic/mami.codi.R/blob/2D_tolerance/man/tolerance_search_plots/Harmonic2DCropped.png?raw=true)
Click here, for the [full 2D tolerance search](https://github.com/homeymusic/mami.codi.R/blob/2D_tolerance/man/tolerance_search_plots/Harmonic2D.jpg) image for the harmonics experiment. Click here, for the
[2D_tolerance branch on GitHub](https://github.com/homeymusic/mami.codi.R/tree/2D_tolerance) to recreate all the 2D searches.\

The best fits across the experiments were given by a frequency tolerance of 
`r default_tolerance(dimension='frequency', scale='macro')`
and a wavelength tolerance of `r default_tolerance(dimension='wavelength', scale='macro')`. 
The frequency tolerance is half the size of the wavelength tolerance. Does that mean that the perception mechanism for frequency 
is twice as discriminating as the wavelength mechanism? "At 1 kHz information contained in temporal discharges was an order of magnitude better than that obtained by a rateâ€“place mechanism. Heinz et al. (2001)" from Winter (2005).\

## Theoretical predictions compared to large-scale behavioral results

The large-scale behavioral data in the plots below are from [Timbral effects on consonance disentangle psychoacoustic mechanisms and suggest perceptual origins for musical scales](https://www.nature.com/articles/s41467-024-45812-z) by Raja Marjieh, Peter M. C. Harrison, Harin Lee, Fotini Deligiannaki & Nori Jacoby.

### Manipulating harmonic frequencies

```{r, include=F}
timbre_paper = readRDS('./man/data/timbre_paper.rds')
```

```{r, include=F}
dyads <- timbre_paper %>% dplyr::rowwise() %>% dplyr::mutate(
  type          = metadata$type,
  num_harmonics = metadata$num_harmonics,
  octave_ratio  = metadata$octave_ratio,
  semitone      = metadata$semitone,
  scale         = metadata$scale,
  label         = round(metadata$semitone),
  chord_max     = max(frequencies),
  chord_min     = min(frequencies),
  .before=1
)
```

```{r, fig.height=8, fig.width=12, echo=F, results='asis', message=F}
params = list(
  list(h=10,o=2.0,s='macro'),
  list(h=5, o=2.0,s='macro'),
  list(h=5,o=2,s='5PartialsNo3'),
  list(h=1, o=2.0,s='Pure'),
  list(h=10,o=2.1,s='macro'),
  list(h=10,o=1.9,s='macro'),
  list(h=4,o=2,s='Bonang'),
  list(h=10,o=2.0,s='M3'),
  list(h=10,o=2.0,s='M6'),
  list(h=10,o=2.0,s='P8')
)

p = params %>% purrr::map(\(p) {
  gray_vlines = c()
  black_vlines = c()
  description = ''
  if (p$o==2 & p$h==10 & p$s == 'macro') {
    timbre = 'Harmonic'
    black_vlines  = c(2,3,4,5,7,8,9,12)
    description   = '   For 10 harmonics, behavioral results and theoretical predictions agree.'
  } else if (p$o==2 & p$h==5 & p$s == 'macro') {
    timbre = '5Partials'
    black_vlines  = c(3,4,5,7,9,12,14)
    description = '  For 5 harmonics, behavioral results and theoretical predictions agree. For comparison with the study below (5 partils with the third partial deleted), notice that the m3 peak is only slightly lower than the M3 peak.'
  } else if (p$o==2 & p$h==5 & p$s == '5PartialsNo3') {
    timbre = '5PartialsNo3'
    black_vlines  = c(4,5,7,9,12,14)
    description = '  For 5 harmonics with the 3rd partial deleted, behavioral results and theoretical predictions mostly agree. As expected, the m3 peak without the third partial is now lower than the m3 peak with all 5 harmonics while the M3 peak is slightly higher without the 3rd partial.'
  } else if (p$o==2 & p$h==1 & p$s == 'Pure') {
    timbre = 'Pure'
    black_vlines  = c(7,12)
    description = '  For pure tones, the behavioral results and the theoretical predictions mostly agree. Only P5 and P8 have pronounced two-sided peaks. The behavioral results show subtle variations in consonance height across the 15 semitones but the overall peak structure agrees with MaMi.CoDi predictions. Theoretical predictions for major-minor versus the beharvoiral results are included in a plot further below.'
  } else if (p$o>2 & p$s == 'macro') {
    timbre = 'Stretched'
    black_vlines  = c(4.2,7.5,9.3,12.78)
    description = '  For stretched harmonics, behavioral results and theoretical predictions mostly agree. MaMi.Codi predicts peaks with minor polarity just above m3 and m7 that do not exist in the behavioral results.'
  } else if (p$o<2 & p$s == 'macro') {
    timbre = 'Compressed'
    black_vlines  = c(3.8,4.8,11.1,14.5)
    description = '  For compressed harmonics, the pronounced behavioral peaks mostly agree with the theoretical peaks.'
  } else if (p$s == 'Bonang') {
    timbre = 'Bonang'
    black_vlines = c(2.60, 4.80, 11.98)
    gray_vlines  = c(7.2, 9.6)
    description = "  For gamalan dyads with a harmonic bass pitch and bonang upper pitch, behavioral results and theoretical predictions mostly agree. MaMi.CoDi predicts a dissonance trough with minor polarity at P4 that is not in the behavioral results.  MaMi.CoDi predicts P5 to have minor polarity and be relatively higher than the behavioral results."
  } else if (p$s == 'M3') {
    timbre = 'M3'
    gray_vlines = c(hrep::freq_to_midi(hrep::midi_to_freq(60) * 5/4)-60,4,4.092442)
    black_vlines  = c(3.95)
    description = '  Description is below.'
  } else if (p$s == 'M6') {
    timbre = 'M6'
    gray_vlines = c(hrep::freq_to_midi(hrep::midi_to_freq(60) * 5/3)-60,9,8.66952)
    black_vlines  = c(8.78,8.93)
    description = '  Description is below.'
  } else if (p$s == 'P8') {
    timbre = 'P8'
    gray_vlines = c(hrep::freq_to_midi(hrep::midi_to_freq(60) * 2/1)-60)
    black_vlines  = c(11.94, 12.08)
    description = '  Description is below.'
  }
  title = paste(
    timbre,
    '~',
    'Partials:', p$h
  )
  
  chords <- dyads %>% dplyr::filter(num_harmonics  == p$h &
                                      octave_ratio == p$o &
                                      scale        == p$s)
  chords$consonance_dissonance_z = z_scores(chords$consonance_dissonance)
  
  experiment.rds = paste0('./man/data/',
                          timbre,
                          '.rds')
  
  experiment_all = readRDS(experiment.rds)
  
  experiment = experiment_all$profile %>%
    dplyr::rename(semitone=interval)
  
  experiment <- experiment %>% dplyr::mutate(
    consonance_dissonance = rating
  )
  
  experiment_raw = experiment_all$data %>% 
    dplyr::rename(semitone=interval, 
                  consonance_dissonance_z=rating)
  
  if (p$s == 'macro' | p$s == 'Bonang' | p$s == '5PartialsNo3' | p$s == 'Pure') {
    sigma = BEHAVIOURAL_SMOOTH_BROAD
  } else {
    sigma = BEHAVIOURAL_SMOOTH_NARROW
  }
  if (timbre=='Harmonic') {
    cat('  \n#### Dyads spanning 15 semitones\n')
  }
  if (timbre=='M3') {
    cat('  \n#### Dyads spanning 1 quarter tone\n')
  }
  cat("  \n#####", title, '\n')
  cat(description)
  print(knitr::kable(tibble::tibble_row(
    detected_pseudo_octave  = paste(round(chords$pseudo_octave %>% unique, 2), collapse = ' '),
    ignore_amplitudes_below = paste(round(chords$min_amplitude %>% unique, 2), collapse = ' '),
    wavelength_tolerance    = paste(round(chords$tolerance %>% unique, 5), collapse = ' '),
    frequency_tolerance     = paste(round(chords$tolerance %>% unique, 5) / 2.0, collapse = ' '),
    smoothing_sigma         = sigma
  )))
  print(plot_semitone_codi(chords, paste('Consonance-Dissonance'),
                           goal=experiment,sigma=sigma,
                           black_vlines=black_vlines,gray_vlines=gray_vlines))
  cat("  \n")
  if (timbre=='Pure') {
  cat("  For pure tones, MaMi.CoDi's theoretical predictions for major-minor have similar contours to the behavioral results for consonance-dissonance.")
  print(plot_semitone_mami(chords, paste('Major-Minor'),
                           goal=experiment,sigma=sigma,
                           black_vlines=black_vlines,gray_vlines=gray_vlines))
  cat("  \n")
  }
})
```

```{r, child=c('man/M3_M6_P8.Rmd')}
```

#### Notes on plots:

In the plots above:

* The cream lines are smoothed experimental data from Marjieh, Harrison et al.

* The multi-colored points are MaMi.CoDi computational predictions

* The multi-colored lines are smoothed MaMi.CoDi computational predictions

* The colors represent MaMi.CoDi computational predictions for major-minor polarity:
* Gold is major
* Red is neutral
* Blue is minor

* The vertical axis is z-scored consonance-dissonance

* The horizontal axis is the width of the dyad from 0 to 15 semitones
* For example, the data at 4 represents the equal tempered major third, M3
* While the data at 8 represents the equal tempered minor sixth, m6
