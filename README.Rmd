---
title: "MaMi.CoDi: A Quantized Model of Consonance Perception at the Classical Uncertainty Limit"
output:
  github_document: default
---

```{r, echo=F, message=F, include=F}
devtools::load_all(".")
source('./man/code/plot.R')
source('./man/code/utils.R')
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  warning = FALSE, 
  message = FALSE
)
remove_floating_point_mistakes <- function(errors, variance) {
  errors = errors[errors>=-variance]
  errors[errors<=variance]
}
```

## Quantum Consonance Perception

### Angular Frequency

A fourier transform from wavenumber to angular frequency.

$$\psi(\omega, t) = \int \phi(k) e^{-i \left( \omega t - k x \right) } dk$$

### Wavenumber

A fourier transform from angular frequency to wavenumber.

$$\phi(k, t) = \int \psi(\omega, t) e^{-i \left( k x \right) } d\omega$$

### Uncertainty

The model is quantized and uncertainty introduced when transforming 
period and frequency ratios to rational fractions using the Stern-Brocot 
tree with variance $\sigma^2$. In our model, the more we know about the 
period of a wave, the less we know about its frequency. \

$$\lambda=\frac{2 \pi}{k}$$

$$f=\frac{\omega}{2 \pi}$$

$${\sigma_f}^2 {\sigma_\lambda}^2 \ge \frac{1} {16 \pi^2}$$

The uncertainty equality holds if the underlying function is normalized to 1, like a 
probability distribution.\

Following Stolzenberg, our model uses the Stern-Brocot tree to approximate 
rational fractions within a given variance. In that sense the values are zero
outside the variance and the probability of finding an approximation is 100%.
So we will assume the equality condition is met, so that:\

$${\sigma_f}^2 {\sigma_\lambda}^2 = \frac{1} {16 \pi^2}$$

When period and frequency variance are the same:\

$$\sigma^2 = {\sigma_f}^2 = {\sigma_\lambda}^2$$

We have: \

$$\sigma^2 = \sqrt{\frac{1} {16 \pi^2}} = \frac{1}{4 \pi} \approx 0.08$$

#### Some Thoughts on Uncertainty

Uncertainty in our model is not the time duration and frequency uncertainty 
$\Delta t \Delta f \simeq 1$ of Gabor or Wiener's famous quantum physics and 
music analogy. If in Gabor (1946) Fig. 1.4 (b) the bank of reeds measured 
periods in a stationary state at $t=0$ instead of frequencies then his 2D 
model would be akin to ours. Our model is frequency and period  
uncertainty $\Delta f \Delta \lambda$, closer to the original quantum ideas of 
Einstein and de Broglie.\

$$\lambda=\frac{2 \pi}{k}=\frac{h}{p}$$

$$f=\frac{\omega}{2 \pi}=\frac{E}{h}$$

#### Computing Fundamental Wavelength and Fundamental Frequency of a Chord

```{r, echo=F, message=F}
f0 = 100
num_harmonics = 3
f = 1:num_harmonics * f0
f_formatted = sprintf(f, fmt = '%#.2f')
```

Consider a $`r f0`$ Hz wave with $`r num_harmonics`$ harmonics:

$f_i=`r f_formatted`$ Hz\

If we put those waves in a medium with a wave speed of

```{r, echo=F, message=F}
c_medium = max(f) * min(f)
l=c_medium/f
l_formatted = sprintf(l, fmt = '%#.2f')
```

$c = max(f) * min(f) = `r c_medium`$

for an infinitely long time then the range of values for the periods 
$\lambda = \frac{c}{f}$ will be the same as the range for the frequencies:

$\lambda_i=`r l_formatted`$ m\

Lets calculate the overall cycle of the whole wave with harmonics twice, using 
a traditional signal processing technique. We will find the frequency and 
period ratios as rational fractions using the Stern-Brocot tree with variances
at the Heisenberg limit and then compute the least common denominator (LCD) for 
each. Using the LCD we will find the overall cycle. \

But a quick glance at the normalized period and frequency values, above, will 
show us that we are headed for a disagreement: the denominators of those ratios 
will not be the same (even with complete precision) and ultimately we will have 
two different values for the overall cycle.\

Frequency Ratios

```{r, echo=F, message=F, results='asis'}
f_ratios = (f / min(f)) %>% sort()
l_ratios = (l / min(l)) %>% sort()
f_rational = approximate_rational_fractions(f_ratios, default_variance(), default_octave_deviation())
print(knitr::kable(f_rational %>% dplyr::select(num, den)))
```

Wavelength Ratios

```{r, echo=F, message=F, results='asis'}
l_rational = approximate_rational_fractions(l_ratios, default_variance(), default_octave_deviation())
print(knitr::kable(l_rational %>% dplyr::select(num, den)))
```

And the period(s) is (are?):

```{r, echo=F, message=F, results='asis'}
results = tibble::tibble(
  frequency_lcd  = lcm_integers(f_rational$den),
  f_whole        = min(f) / frequency_lcd,
  T_from_f       = 1 / f_whole,
  period_lcd = lcm_integers(l_rational$den),
  l_whole        = max(l) * period_lcd,
  T_from_l       = l_whole / c_medium
)
T_from_f = results$T_from_f
T_from_l = results$T_from_l
print(knitr::kable(
  results  
))
```

From the frequency perspective, the period of the whole wave is $`r T_from_f`$ s.\

From the period (space) perspective, the period of the whole wave is $`r T_from_l`$ s.\

The periods disagree. The disagreement is not due to a lack of precision in the 
sensors or the time duration that the waves were in the medium or even the rational 
fraction approximation ($3/2$ is precisely $150/100$). The disagreement seems 
to be a fundamental difference in the way the pattern would be perceived between
period and frequency sensors. This disagreement at the level of pattern 
recognition of the combined wave is not the same as the uncertainty between 
the period and frequency of each partial in the wave, above.\

## How MaMi.CoDi is Implemented

 ### The Math

#### Traveling Waves

$$s_{i}(x, t) = \sin \left( \frac{2\pi x}{\lambda_{i}} - 2 \pi f_{i} t \right)$$
$N$ is the number of traveling waves in the chord.

$$i=1...N$$

#### Fundamental Wavelength

$$\lambda_{0} = \lambda_{max} { ALCD}\left(r_{\lambda 1},..., r_{\lambda N}\right)$$
$ALCD()$ is an approximate least common denominator.\

#### Wavelength Ratios\

$$r_{\lambda i} = \frac{\lambda_{i}}{\lambda_{min}} \pm \sigma_{\lambda}^{2} = \frac{a_{i}}{b_{i}}$$

$${ GCD}(a_{i}, b_{i}) = 1$$
$GCD()$ is the greatest common divisor.\

#### Fundamental Frequency

$$f_{0} = f_{min} / { ALCD}\left(r_{f 1},..., r_{f N}\right)$$
Frequency Ratios

$$r_{f i} = \frac{f_{i}}{f_{min}} \pm \sigma_{f}^{2} = \frac{c_{i}}{d_{i}}$$


$${GCD}(c_{i}, d_{i}) = 1$$

#### Heisenberg Uncertainty

$$\sigma_{\lambda}^{2} \sigma_{f}^{2} = \frac{1}{16\pi^{2}}$$

The Stern-Brocot approximation is 0 outside $\pm\sigma^{2}$ which satisfies the
exponential decay constraint and so we can presume equality.

#### Consonance Perception

Spatial Consonance

$$C_{\lambda} = 50- \log_{2}\left({ ALCD}\left(r_{\lambda 1},..., r_{\lambda N}\right)\right)$$
Temporal Consonance

$$C_{f} = 50 - \log_{2}\left({ ALCD}\left(r_{f 1},..., r_{f N}\right)\right)$$

Total Consonance

$$C_{\lambda f} = C_{\lambda} + C_{f}$$

Pure tone will have a total consonance $C_{\lambda f}$ of 100.

Major-Minor

$$M_{\lambda f} = C_{f} - C_{\lambda}$$
Neutral chords will have a major-minor value $M_{\lambda f}$ of 0.

### The Basilar Membrane

When a chord is sounded, pressure waves travel through the air. Those pressure
waves enter the ear canal where they vibrate the ear drum. The ear drum transfers
the energy of the pressure waves through a series of bones in the fluid of the 
middle ear to an oval window on the shell-shaped cochlea of the inner ear. 
Within the fluid of the cochlea, the sound energy is converted into a traveling 
surface wave along the basilar membrane.\

Human basilar membranes are around 33 mm long. Thousands of evenly-spaced hair 
cells are arranged in a line on the basilar membrane. The hair cells transduce
mechanical vibrations into electrical activity that is sent along the auditory 
nerve to the central auditory system. When a sound wave travels along the basilar 
membrane, the hair cells positioned near the period of that sound will send 
electrical activity along the auditory nerve.\

The fundamental tone of middle C is over a meter long
in room temperature air at sea level. But the basilar membrane is only 33mm long. 
How can the hair cells positioned along the basilar membrane detect periods that are
longer than the entire basilar membrane?\

The traveling sound waves shorten as they travel around the spiral
cochlea. Middle C's fundamental period of 1.31 meters in air shrinks to 
26 mm along the basilar membrane. So, when the fundamental tone of middle C is 
sounded, the hair cells positioned 26 mm (81%) from the base of the cochlea
send electrical activity along the auditory nerve.\

When a musical chord comprised of many fundamental tones and harmonics is sounded,
the hair cells at each shortened period position send signals along 
the auditory nerve. This period or rate-place arrangement of hair cell positions and 
periods of tones is known as tonotopy.\

### The Core Idea of MaMi.CoDi

If we play a chord, freeze time and observe which hair cells are displaced, what 
are we observing? Are we observing frequencies? Periods? No. Time is frozen.
Frequency (1/s) and period (s) are frequency observations. We are making a purely 
period observation about periods (m). We will come back to frequency
observations shortly.\

When we combine all the component parts of a chord together into a whole, 
we can estimate the overall period for the whole chord. A technique used in digital signal 
processing and bricklaying is to estimate ratios (within an acceptable variance)
between each of the parts and a selected reference part.
The greatest common divisor (LCD) of those part ratios will be a measure of the periodicity 
of the whole.\

Chords with short periods relative to the component periods sound pleasant. 
And chords with long periods relative to component periods sound unpleasant. 
MaMi.CoDi uses this measure of relative periods to predict the 
perceived period consonance of a chord.\

Let us unfreeze time and start counting how often a hair cell moves due to a 
pure tone of our sounded chord. If we count the number of movements relative to a
certain amount of time, we will be observing the frequency of the partial. 
This would be a frequency observation. The auditory system has a property called 
phase locking which allows it to encode the time intervals, periods, between spikes from 
sound waves.\

When we combine the period components of a chord together, we can estimate 
the overall period for the whole chord. That chord period will be as long as
or longer than the longest component period of the chord. Short relative periods
sound pleasant. Long relative periods sound unpleasant.
MaMi.CoDi uses this measure of chord period to predict the perceived frequency 
consonance of a chord.\

MaMi.CoDi sums the period and frequency consonance predictions to create
an overall consonance-dissonance prediction. MaMi.CoDi subtracts
the period consonance from the frequency consonance to create a major-minor polarity 
prediction. Positive values will sound major, negative values minor and values 
around zero will sound neutral.\

Because period and frequency are inverse of each other one might imagine that 
the period and frequency signals would have the same values. However, for complex 
pitches that is not the case. The pattern of the two sets of components are different.
See the example of the major triad with 5 harmonics, below.

```{r, child=c('./man/Spatiotemporal_Periodicity.Rmd')}
```

### Finding the variance Values

"One difficulty with distinguishing between place and frequency (or place-time) models of
pitch is that spectral and frequency representations of a signal are mathematically equivalent:
any change in the spectral representation is reflected by a change in the frequency
representation, and vice versa . Discovering what the auditory system does means focusing
on the physiological limits imposed by the cochlea and auditory nerve.\

"For instance, the
place theory can be tested using known limits of frequency selectivity: if pitch can be heard
when only unresolved harmonics are presented (eliminating place information), then place
information is not necessary for pitch. Similarly, if all the frequencies within a stimulus are
above the upper limits of phase locking, and the frequency envelope information is somehow
suppressed, then frequency information is not necessary for pitch perception."\

from "Revisiting place and frequency theories of pitch", Andrew J. Oxenham, 2014.\

The MaMi.CoDi model, based on Stolzenburg (2015), has one one parameter: 
variance. Variance is used by the Stern-Brocot algorithm to find tone
ratios as rational fractions that are then used to estimate the relative 
periodicity of chords. variance acts as the physiological limits mentioned by 
Oxenham, above.\

Considering that the period and frequency signals had two different physiological
origins, we searched a two-dimensional variance space in order to match model
predictions with the large-scale behavioral results. It turned out that the 
values that best matched large-scale behavioral results were always the
same for frequency and period variance. This might indicate that the physiological 
limitations are not specific to place signals or time signals separetely. But 
instead the limitation is higher in the auditory system after the signals have
been passed along.\

That is to say, the limits that creates differences between frequency and period 
signals might not be frequency selectivity or phase locking but instead a limit
of higher-level perception or pattern recognition, where estimates of the period 
of a complex signal is made from components.\

MaMi.CoDi uses the Stern-Brocot tree to find rational fractions for the ratios 
within a given variance. How do we find the best variance values? For the 
MaMi.CoDi model we ran thousands of computations with various variance values 
and compared the predictions with results from six of the large-scale behavioral 
experiments.\

Because the period signal and the frequency signal have different origins
we initially did a two-dimensional variance search. However the closest 
fits to the behavioral data came from period and variance values being the 
same. Insofar as this model represents processing in the auditory cortex, it 
would seem that estimating the cyclicity of the two signals happens higher up
in the auditoray system after the period and frequency signals have been processed.\


### Difference between Stern-Brocot Rational Fraction Approximations and Floating Point Values

```{r, echo=F, message=F}
variance = default_variance()
path = paste0('./man/data/stern_brocot_',variance,'.rds')
fractions = readRDS(path)
```

```{r, echo=F, message=F}
print(plot_error_hist(fractions$error,
                      bins=21,
                      'fundamental', 
                      variance,
                      'Stern-Brocot Curve'))
cat("  \n")

```
Number of Samples: `r fractions %>% nrow() %>% format(big.mark=',',scientific=F,trim=T)` \

[Additional Stern-Brocot Plots](/man/thoughts/SternBrocotCurve.md)

The Stern-Brocot curve is a repeatable, deterministic curve of where rational 
fractions exist or do not exist within a given variance.\

However, the value is 0 outside $\pm \sigma^{2}$ and the area of the 
curve equals one so that we can use it like a probability density 
function.\ 

When I see the shape of this curve of rational numbers at the Heisenberg limit
I can't help but think about the double-slit experiment and chance versus 
determinism, in general.\

Perhaps things are quantized but not probabilistic?\

Maybe God does not play dice with the universe. Whatever the game, God keeps 
score with rational fractions at the Heisenberg limit.\

## Theoretical predictions compared to large-scale behavioral results

The large-scale behavioral data in the plots below are from [Timbral effects on consonance disentangle psychoacoustic mechanisms and suggest perceptual origins for musical scales](https://www.nature.com/articles/s41467-024-45812-z) by Raja Marjieh, Peter M. C. Harrison, Harin Lee, Fotini Deligiannaki & Nori Jacoby.

### Manipulating harmonic frequencies

```{r, include=F}
timbre_paper = readRDS('./man/data/readme.rds')
```

```{r, include=F}
dyads <- timbre_paper %>% dplyr::rowwise() %>% dplyr::mutate(
  type          = metadata$type,
  num_harmonics = metadata$num_harmonics,
  octave_ratio  = metadata$octave_ratio,
  semitone      = metadata$semitone,
  timbre        = metadata$timbre,
  label         = round(metadata$semitone),
  chord_max     = max(frequencies),
  chord_min     = min(frequencies),
  .before=1
)
```

```{r, fig.height=8, fig.width=12, echo=F, results='asis', message=F}
params = list(
  list(h=1, o=2.0,t='Pure'),
  list(h=10,o=2.0,t='Harmonic'),
  list(h=5, o=2.0,t='5Partials'),
  list(h=5, o=2.0,t='5PartialsNo3'),
  list(h=4, o=2.0,t='Bonang'),
  list(h=10,o=2.1,t='Stretched'),
  list(h=10,o=1.9,t='Compressed'),
  list(h=10,o=2.0,t='M3'),
  list(h=10,o=2.0,t='M6'),
  list(h=10,o=2.0,t='P8'),
  list(h=10,o=2.0,t='P8ZoomedTemporal'),
  list(h=10,o=2.0,t='P8ZoomedSpatial')
)

BEHAVIOURAL_SMOOTH_BROAD  <- 0.2
BEHAVIOURAL_SMOOTH_NARROW <- 0.035

p = params %>% purrr::map(\(p) {
  gray_vlines = c()
  black_vlines = c()
  description = ''
  
  if (p$o==2 & p$h==10 & p$t == 'Harmonic') {
    black_vlines  = c(2,3,4,5,7,8,9,12)
    description   = '   For 10 harmonics, behavioral results and theoretical predictions agree.'
    sigma = BEHAVIOURAL_SMOOTH_BROAD
  } else if (p$o==2 & p$h==5 & p$t == '5Partials') {
    black_vlines  = c(3,4,5,7,9,12,14)
    description = '  For 5 harmonics, behavioral results and theoretical predictions agree. For comparison with the study below (5 partils with the third partial deleted), notice that the m3 peak is only slightly lower than the M3 peak.'
    sigma = BEHAVIOURAL_SMOOTH_BROAD
  } else if (p$o==2 & p$h==5 & p$t == '5PartialsNo3') {
    black_vlines  = c(4,5,7,9,12,14)
    description = '  For 5 harmonics with the 3rd partial deleted, behavioral results and theoretical predictions mostly agree. As expected, the m3 peak without the third partial is now lower than the m3 peak with all 5 harmonics while the M3 peak is slightly higher without the 3rd partial.'
    sigma = BEHAVIOURAL_SMOOTH_BROAD
  } else if (p$o==2 & p$h==1 & p$t == 'Pure') {
    black_vlines  = c(7,12)
    description = '  For pure tones, the behavioral results and the theoretical predictions mostly agree. Only P5 and P8 have pronounced two-sided peaks. The behavioral results show subtle variations in consonance height across the 15 semitones but the overall peak structure agrees with MaMi.CoDi predictions. For futher comparison, the theoretical predictions for major-minor versus the behavioral results are included in a plot below.'
    sigma = BEHAVIOURAL_SMOOTH_BROAD
  } else if (p$o>2 & p$t == 'Stretched') {
    black_vlines  = c(4.2,7.5,9.4,12.78)
    description = '  For stretched harmonics, behavioral results and theoretical predictions mostly agree. MaMi.Codi predicts peaks with minor polarity just above m3 and m7 that do not exist in the behavioral results.'
    sigma = BEHAVIOURAL_SMOOTH_BROAD
  } else if (p$o<2 & p$t == 'Compressed') {
    black_vlines  = c(3.8,4.8,11.1,14.5)
    description = '  For compressed harmonics, the pronounced behavioral peaks mostly agree with the theoretical peaks.'
    sigma = BEHAVIOURAL_SMOOTH_BROAD
  } else if (p$t == 'Bonang') {
    black_vlines = c(2.60, 4.80, 12.0)
    gray_vlines  = c(7.2, 9.6)
    description = "  For gamalan dyads with a harmonic bass pitch and bonang upper pitch, behavioral results and theoretical predictions mostly agree. MaMi.CoDi predicts a dissonance trough with minor polarity at P4 that is not in the behavioral results.  MaMi.CoDi predicts P5 to have minor polarity and be relatively higher than the behavioral results."
    sigma = BEHAVIOURAL_SMOOTH_BROAD
  } else if (p$t == 'M3') {
    gray_vlines = c(hrep::freq_to_midi(hrep::midi_to_freq(60) * 5/4)-60,4,4.092442)
    black_vlines  = c(3.95)
    description = '  Description is below.'
    sigma = BEHAVIOURAL_SMOOTH_NARROW
  } else if (p$t == 'M6') {
    gray_vlines = c(hrep::freq_to_midi(hrep::midi_to_freq(60) * 5/3)-60,9,8.66952)
    black_vlines  = c(8.78,8.93)
    description = '  Description is below.'
    sigma = BEHAVIOURAL_SMOOTH_NARROW
  } else if (p$t == 'P8') {
    gray_vlines = c(hrep::freq_to_midi(hrep::midi_to_freq(60) * 2/1)-60)
    black_vlines  = c(11.94, 12.08)
    description = '  Description is below.'
    sigma = BEHAVIOURAL_SMOOTH_NARROW
  } else if (p$t == 'P8ZoomedTemporal') {
    gray_vlines = c(hrep::freq_to_midi(hrep::midi_to_freq(60) * 2/1)-60)
    black_vlines  = c(11.94, 12.08)
    description = '  Due to the Heisenberg uncertainty principle, focusing on 
    one signal (frequency) is akin to shutting off the other (period).'
    sigma = BEHAVIOURAL_SMOOTH_NARROW
  } else if (p$t == 'P8ZoomedSpatial') {
    gray_vlines = c(hrep::freq_to_midi(hrep::midi_to_freq(60) * 2/1)-60)
    black_vlines  = c(11.94, 12.08)
    description = '  Due to the Heisenberg uncertainty principle, focusing on 
    one signal (period) is akin to shutting off the other (frequency).'
    sigma = BEHAVIOURAL_SMOOTH_NARROW
  }
  title = paste(
    p$t,
    '~',
    'Partials:', p$h
  )
  
  chords <- dyads %>% dplyr::filter(timbre == p$t)
  chords$consonance_dissonance_z = z_scores(chords$consonance_dissonance)
  chords$major_minor_z = z_scores(chords$major_minor)
  chords$period_consonance_z = z_scores(chords$period_consonance)
  chords$frequency_consonance_z = z_scores(chords$frequency_consonance)
  
  experiment.rds = paste0('./man/data/',
                          p$t,
                          '.rds')
  
  experiment_all = readRDS(experiment.rds)
  
  experiment = experiment_all$profile %>%
    dplyr::rename(semitone=interval)
  
  experiment <- experiment %>% dplyr::mutate(
    consonance_dissonance = rating
  )
  
  experiment_raw = experiment_all$data %>% 
    dplyr::rename(semitone=interval, 
                  consonance_dissonance_z=rating)
  
  if (p$t=='Pure') {
    cat('  \n#### Dyads spanning 15 semitones\n')
  }
  if (p$t=='M3') {
    cat('  \n#### Dyads spanning 1 quarter tone\n')
  }
  cat("  \n#####", title, '\n')
  cat(description)
  t_v = chords$frequency_variance %>% unique() %>% max()
  s_v = chords$period_variance %>% unique() %>% max()
  print(knitr::kable(tibble::tibble_row(
    frequency_variance = paste(round(t_v, 5), collapse = ' '),
    period_variance  = paste(round(s_v, 5), collapse = ' '),
    smoothing_sigma   = sigma
  )))
  
  print(plot_semitone_codi(chords, paste('Consonance-Dissonance'),
                           goal=experiment,sigma=sigma,include_points=T,
                           black_vlines=black_vlines,gray_vlines=gray_vlines))
  cat("  \n")
  
  print(plot_semitone_period_frequency(chords, paste('Spatial and Temporal Consonance'),
                                       goal=NULL,sigma=sigma,include_points=T,
                                       black_vlines=black_vlines,gray_vlines=gray_vlines))
  cat("  \n")
  
  print(plot_semitone_mami(chords, paste('Major-Minor'),
                           goal=NULL,sigma=sigma,include_points=T,
                           black_vlines=black_vlines,gray_vlines=gray_vlines))
  cat("  \n")
  
  frequency_error = (chords %>% tidyr::unnest(frequency_fractions))$error
  frequency_error = remove_floating_point_mistakes(frequency_error, t_v)
  print(plot_error_hist(frequency_error, bins=21, 'major', t_v, 'Temporal Variance'))
  cat("  \n")
  
  period_error = (chords %>% tidyr::unnest(period_fractions))$error
  period_error = remove_floating_point_mistakes(period_error, s_v)
  print(plot_error_hist(period_error,  bins=21, 'minor', s_v, 'Spatial Variance'))
  cat("  \n")
  
})
```

### Manipulating amplitudes

```{r, include=F}
timbre_paper = readRDS('./man/data/roll_off_timbre_paper.rds')
```

```{r, include=F}
dyads <- timbre_paper %>% dplyr::rowwise() %>% dplyr::mutate(
  type          = metadata$type,
  num_harmonics = metadata$num_harmonics,
  octave_ratio  = metadata$octave_ratio,
  semitone      = metadata$semitone,
  roll_off      = metadata$roll_off,
  label         = round(metadata$semitone),
  .before=1
)
```

```{r, include=F}
params = list(
  list(h=10,r=12),
  list(h=10,r=7),
  list(h=10,r=2)
)
```

```{r, fig.height=8, fig.width=12, echo=F, results='asis', message=F}
p = params %>% purrr::map(\(p) {
  gray_vlines = c()
  if (p$r == 2) {
    black_vlines = c(3,4,5,7,8,9,12)
  } else if (p$r == 7) {
    black_vlines = c(4,5,6,7,9,12)
  } else if (p$r == 12) {
    black_vlines = c(3,4,5,7,8,9,12)
  }
  title = paste(
    'Harmonic ~',
    'Roll Off:', p$r
  )
  
  chords <- dyads %>% dplyr::filter(roll_off == p$r)
  chords$consonance_dissonance_z = z_scores(chords$consonance_dissonance)
  
  experiment.csv = paste0('./man/data/',
                          'roll_off_', p$r,
                          '.csv')
  
  experiment = read.csv(experiment.csv) %>%
    dplyr::rename(semitone=interval)
  
  experiment <- experiment %>% dplyr::mutate(
    consonance_dissonance = rating
  )
  sigma = BEHAVIOURAL_SMOOTH_BROAD
  cat("  \n#####", title, '\n')
  print(knitr::kable(tibble::tibble_row(
    frequency_variance = paste(round(chords$frequency_variance %>% unique, 5), collapse = ' '),
    period_variance  = paste(round(chords$period_variance %>% unique, 5), collapse = ' '),
    min_amplitude       = paste(round(chords$minimum_amplitude %>% unique, 5), collapse = ' '),
    smoothing_sigma = sigma
  )))
  print(plot_semitone_codi(chords, paste('Consonance-Dissonance'),
                           goal=experiment,sigma=sigma,include_points=T,
                           black_vlines=black_vlines,gray_vlines=gray_vlines))
  cat("  \n")
  
  print(plot_semitone_period_frequency(chords, paste('Spatial and Temporal Consonance'),
                                       goal=NULL,sigma=sigma,include_points=T,
                                       black_vlines=black_vlines,gray_vlines=gray_vlines))
  cat("  \n")
})
```

#### Notes on plots:

In the plots above:

* The cream lines are smoothed experimental data from Marjieh, Harrison et al.

* The multi-colored points are MaMi.CoDi computational predictions

* The multi-colored lines are smoothed MaMi.CoDi computational predictions

* The colors represent MaMi.CoDi computational predictions for major-minor polarity:
* Gold is major
* Red is neutral
* Blue is minor

* The vertical axis is z-scored consonance-dissonance

* The horizontal axis is the width of the dyad from 0 to 15 semitones
* For example, the data at 4 represents the equal tempered major third, M3
* While the data at 8 represents the equal tempered minor sixth, m6
